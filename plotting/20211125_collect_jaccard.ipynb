{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T15:24:13.508761Z",
     "start_time": "2021-12-01T15:23:42.024112Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob \n",
    "import os \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import pickle\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#See # heatmap_collect.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T15:24:51.361336Z",
     "start_time": "2021-12-01T15:24:13.511892Z"
    }
   },
   "outputs": [],
   "source": [
    "tar_file_OHSU = '/cluster/work/grlab/projects/projects2020_OHSU/share_OHUS_PNLL/Aug21_graph_data_current/OHSU_kmer_lists_Nov24.tar.gz'\n",
    "\n",
    "base_folder_ETH = '/cluster/work/grlab/projects/projects2020_OHSU/peptides_generation/v2_v2.5f0752a_conf2_annotFrame_cap0_runs_pya0.17.1/TCGA_Breast_1102'\n",
    "\n",
    "def ohsu_to_eth(path):\n",
    "    cohort = {'NormalCohortcore_GTEx_': 'Gtexcore', \n",
    "             'NormalCohortpaired_': 'Matched', \n",
    "             'NormalCohortAll_':'Alls'}\n",
    "    \n",
    "    key_to_apply = [k for k in cohort if k in path]\n",
    "    if key_to_apply: \n",
    "        key_to_apply = key_to_apply[0]\n",
    "        path = path.replace(key_to_apply, '')\n",
    "        path = path.replace('FiltNormalsC','FiltNormals{}C'.format(cohort[key_to_apply]) )\n",
    "\n",
    "        path = path.replace('J_', 'G_')\n",
    "\n",
    "        path = path.replace('CohortLim', '.0CohortLim')\n",
    "        sample = path.split('_')[1]\n",
    "        #print(path)\n",
    "        return path, sample\n",
    "    else:\n",
    "        return None, None \n",
    "\n",
    "def get_eth_path(base_folder_ETH, name_eth=None, sample=None):\n",
    "    path_o = None \n",
    "    if name_eth is not None: \n",
    "        path_list = os.path.join(base_folder_ETH, 'filter_' + sample, '*', name_eth, 'part*')\n",
    "        path_list = glob.glob(path_list)\n",
    "        if path_list:\n",
    "            path_o = path_list[0]\n",
    "    return path_o \n",
    "    \n",
    "\n",
    "def set_stats(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    jaccard = float(intersection) / union\n",
    "    return intersection, union, intersection/len(list1), intersection/len(list2), jaccard\n",
    "     \n",
    "\n",
    "\n",
    "def save_picke(i, sizes_ohsu, sizes_eth, sizes_intersect, \n",
    "              sizes_union, percent_ohsu_in_eth, percent_eth_in_ohsus, \n",
    "              jaccard):\n",
    "    filehandler = open(b\"/cluster/work/grlab/projects/projects2020_OHSU/plots/heatmaps/stats{}.pickle\".format(i),\"wb\")\n",
    "    res = [sizes_ohsu ,\n",
    "    sizes_eth ,\n",
    "    sizes_intersect, \n",
    "    sizes_union ,\n",
    "    percent_ohsu_in_eth, \n",
    "    percent_eth_in_ohsus,\n",
    "    jaccard ]\n",
    "    pickle.dump(res,filehandler)\n",
    "\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "\n",
    "file_pair = {'eth':[], 'ohsu': []}\n",
    "with tarfile.open(tar_file_OHSU, \"r:*\") as tar:\n",
    "    file_names_OHSU = tar.getnames()\n",
    "\n",
    "    for name_ohsu in file_names_OHSU:\n",
    "        name_eth, sample = ohsu_to_eth(name_ohsu)\n",
    "        eth_path = get_eth_path(base_folder_ETH, name_eth, sample)\n",
    "        if (eth_path is not None) and os.path.isfile(eth_path):\n",
    "            file_pair['eth'].append(eth_path) \n",
    "            file_pair['ohsu'].append(name_ohsu)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T15:24:51.377391Z",
     "start_time": "2021-12-01T15:24:51.365646Z"
    }
   },
   "outputs": [],
   "source": [
    "def path_to_condition(all_paths):\n",
    "    # None handling added \n",
    "    \n",
    "    all_paths = [path.replace('None', '0') for path in all_paths]\n",
    "    sample_expr = [np.float(os.path.basename(path).split('ref_SampleLim')[1].split('Cohort')[0]) \n",
    "                   for path in all_paths ]\n",
    "\n",
    "    foreground_cohort_expr = [np.float(os.path.basename(path).split('CohortLim')[1].split('Across')[0])\n",
    "                                       for path in all_paths ]\n",
    "\n",
    "    foreground_cohort_samples = [np.int(os.path.basename(path).split('Across')[1].split('_Filt')[0] ) \n",
    "                                 for path in all_paths ]\n",
    "\n",
    "    background_cohort_expr = [np.float(os.path.basename(path).split('Cohortlim')[1].split('Across')[0])\n",
    "                              for path in all_paths ]\n",
    "\n",
    "    background_cohort_samples = [np.int(os.path.basename(path).split('Across')[2].split('_FiltUn')[0])\n",
    "                                 for path in all_paths ]\n",
    "    background_cohort_id = [os.path.basename(path).split('Normals')[1].split('lim')[0] for path in all_paths ]\n",
    "\n",
    "    legend_quant = pd.DataFrame({'sample_expr':sample_expr, \n",
    "                  'foreground_cohort_expr': foreground_cohort_expr, \n",
    "                  'foreground_cohort_samples': foreground_cohort_samples, \n",
    "                  'background_cohort_expr': background_cohort_expr,\n",
    "                  'background_cohort_samples' : background_cohort_samples, \n",
    "                    'background_cohort_id':background_cohort_id})\n",
    "\n",
    "\n",
    "    sort_legend = False\n",
    "    if sort_legend:\n",
    "        legend_quant = legend_quant.sort_values(\"background_cohort_samples\", ascending=False).\\\n",
    "        sort_values(\"background_cohort_expr\", ascending=False).\\\n",
    "        sort_values(\"foreground_cohort_samples\", ascending=False).\\\n",
    "        sort_values(\"foreground_cohort_expr\", ascending=False).\\\n",
    "        sort_values(\"sample_expr\", ascending=False)\n",
    "    return legend_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T15:24:51.385187Z",
     "start_time": "2021-12-01T15:24:51.378926Z"
    }
   },
   "outputs": [],
   "source": [
    "def colors_from_values(values, palette_name):\n",
    "    # normalize the values to range [0, 1]\n",
    "    normalized = (values - min(values)) / (max(values) - min(values))\n",
    "    # convert to indices\n",
    "    indices = np.round(normalized * (len(values) - 1)).astype(np.int32)\n",
    "    # use the indices to get the colors\n",
    "    palette = sns.color_palette(palette_name, len(values))\n",
    "    return np.array(palette).take(indices, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-01T16:58:11.512Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_legend(y1, y2, y3, y4, y5, y6, x, save_path=None, save=False):\n",
    "    #sns.set(style=\"white\", context=\"talk\")  \n",
    "    sns.set_style(\"white\")\n",
    "    #, {\n",
    "    #     \"ytick.major.size\": 0.1,\n",
    "    #     \"ytick.minor.size\": 0.05,\n",
    "    #     'grid.linestyle': '--', \n",
    "    #         \"xtick.major.size\": 0.1,\n",
    "    #     \"xtick.minor.size\": 0.05,\n",
    "    #     'grid.linestyle': '--'\n",
    "    #  })\n",
    "    rs = np.random.RandomState(8)  \n",
    "    min_axes = -0.5\n",
    "    y_label_size = 35\n",
    "    x_label_size = 20\n",
    "    # Set up the matplotlib figure  \n",
    "    f, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(1, 6, figsize=(16,10), sharey=True)  \n",
    "    ax1.invert_yaxis()\n",
    "\n",
    "    sns.barplot(x=y1, y=x, palette=colors_from_values(y1, \"YlOrRd\"), ax=ax1, orient=\"h\")  \n",
    "    #ax1.axhline(0, color=\"k\", clip_on=True)  \n",
    "    #ax1.yaxis.set_minor_locator(ticker.MultipleLocator(1))\n",
    "    ax1.set_xlim([min_axes, max(y1)])\n",
    "    ax1.set_ylabel(y1.name, fontsize=y_label_size) \n",
    "    ax1.tick_params(labelsize=x_label_size) \n",
    "\n",
    "\n",
    "    sns.barplot(x=y2, y=x, palette=colors_from_values(y2, \"vlag\"), ax=ax2, orient=\"h\", linewidth=1)  \n",
    "    #ax2.axhline(0, color=\"k\", clip_on=False)  \n",
    "    ax2.set_xlim([min_axes, max(y2)])\n",
    "    ax2.set_ylabel(y2.name, fontsize=y_label_size) \n",
    "    ax2.tick_params(labelsize=x_label_size) \n",
    "\n",
    "    sns.barplot(x=y3, y=x, palette=colors_from_values(y3, \"deep\"), ax=ax3, orient=\"h\")\n",
    "    #ax3.axhline(0, color=\"k\", clip_on=False)  \n",
    "    ax3.set_xlim([min_axes, max(y3)])\n",
    "    ax3.set_ylabel(y3.name, fontsize=y_label_size) \n",
    "    ax3.tick_params(labelsize=x_label_size) \n",
    "    \n",
    "    sns.barplot(x=y4, y=x, palette=colors_from_values(y4, \"turbo\"), ax=ax4, orient=\"h\")\n",
    "    #ax4.axhline(0, color=\"k\", clip_on=False)  \n",
    "    ax4.set_xlim([min_axes, max(y4)])\n",
    "    ax4.set_ylabel(y4.name, fontsize=y_label_size) \n",
    "    ax4.tick_params(labelsize=x_label_size) \n",
    "    \n",
    "    sns.barplot(x=y5, y=x, palette=colors_from_values(y5, \"Accent\"), ax=ax5, orient=\"h\")\n",
    "    #ax5.axhline(0, color=\"k\", clip_on=False)  \n",
    "    ax5.set_xlim([min_axes, max(y5)])\n",
    "    ax5.set_ylabel(y5.name, fontsize=y_label_size) \n",
    "    ax5.tick_params(labelsize=x_label_size) \n",
    "    \n",
    "    sns.scatterplot(x=np.ones(len(x)), y=x, ax=ax6, hue=y6)\n",
    "    #ax6.axhline(0, color=\"k\", clip_on=False)  \n",
    "    #ax.legend(ax6.get_legend(),loc='lower right' ) \n",
    "    ax6.legend(loc='center right', bbox_to_anchor=(1,0))\n",
    "    #ax6.invert_yaxis()\n",
    "    ax6.set_ylabel(y6.name, fontsize=y_label_size) \n",
    "    ax6.tick_params(labelsize=x_label_size, labelbottom=False) \n",
    "\n",
    "    # Finalize the plot  \n",
    "    sns.despine(bottom=True)  \n",
    "    #plt.setp(ax.get_yticklabels(), fontsize=y_label_size, rotation=89)\n",
    "    plt.setp(f.axes, yticks=np.arange(0,len(x),10), xlabel='')\n",
    "\n",
    "    plt.tight_layout(h_pad=1) \n",
    "    ax1.invert_yaxis()\n",
    "    if save:\n",
    "        print(\"save to {}\".format(save_path))\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi = 300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T16:41:23.115265Z",
     "start_time": "2021-12-01T16:41:22.362713Z"
    }
   },
   "outputs": [],
   "source": [
    "def wrapper_legend(all_paths, idx, save_path=None, save=False):\n",
    "    all_paths = np.array(all_paths)[idx]\n",
    "    prep_paths = ['/'.join(path.split('/')[:-1]) for path in all_paths]\n",
    "    legend_quant = path_to_condition(prep_paths)\n",
    "    print(legend_quant.shape)\n",
    "    #Prepare Plot\n",
    "    legend_quant.columns = [col.replace('_', ' ') for col in legend_quant.columns]\n",
    "    y1, y2, y3, y4, y5, y6 = [legend_quant[col] for col in legend_quant.columns]\n",
    "    legend_quant['index'] = np.arange(legend_quant.shape[0])\n",
    "    x = legend_quant['index'] \n",
    "\n",
    "\n",
    "    plot_legend(y1, y2, y3, y4, y5, y6, x, save_path, save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T16:11:43.665720Z",
     "start_time": "2021-12-01T16:11:43.661113Z"
    }
   },
   "outputs": [],
   "source": [
    "def heatmap2d(arr: np.ndarray,  save_path=None, save=False):\n",
    "    #f, ax = plt.subplots(figsize=(7, 5))\n",
    "    plt.imshow(arr, cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    if save:\n",
    "        print(\"save to {}\".format(save_path))\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi = 300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Heatmap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T15:25:05.300496Z",
     "start_time": "2021-12-01T15:24:51.402109Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "key_order = ['sizes_ohsu', \n",
    "'sizes_eth', \n",
    "'sizes_intersect', \n",
    "'sizes_union', \n",
    "'percent_ohsu_in_eth',\n",
    "'percent_eth_in_ohsu', \n",
    "'jaccard']\n",
    "heatmap_data = {}\n",
    "for key in key_order:\n",
    "    heatmap_data[key] = []\n",
    "for i in np.arange(len(file_pair['eth'])):\n",
    "    print(i)\n",
    "    name = \"/cluster/work/grlab/projects/projects2020_OHSU/plots/heatmaps/stats_single{}.pickle\".format(i)\n",
    "    data = pickle.load(open(name, 'rb'))\n",
    "    for idx, key in enumerate(key_order):\n",
    "        heatmap_data[key].append(data[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T15:25:05.308771Z",
     "start_time": "2021-12-01T15:25:05.303242Z"
    }
   },
   "outputs": [],
   "source": [
    "# Subset \n",
    "samples = ['TCGA-A2-A0D2-01A-21R-A034-07', 'TCGA-A2-A0SX-01A-12R-A084-07',\n",
    "           'TCGA-AO-A0JM-01A-21R-A056-07',  'TCGA-BH-A18V-01A-11R-A12D-07', \n",
    "           'TCGA-C8-A12P-01A-11R-A115-07']\n",
    "split_on_criteria =  defaultdict(list)\n",
    "for idx, path in enumerate(file_pair['eth']):\n",
    "    for sample in samples:\n",
    "        if sample in path:\n",
    "            split_on_criteria[sample].append(idx) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-01T16:36:56.869050Z",
     "start_time": "2021-12-01T16:36:56.865306Z"
    }
   },
   "outputs": [],
   "source": [
    "save = False\n",
    "plot_dir = '/cluster/work/grlab/projects/projects2020_OHSU/plots'\n",
    "plot_dir = os.path.join(plot_dir, 'heatmaps', 'figs')\n",
    "base_plot = 'v2_v2.5f0752a_conf2_BRCA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-12-01T16:58:21.018Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot data \n",
    "for criteria, get_idx in split_on_criteria.items():\n",
    "    print(criteria)\n",
    "    base_sample =  base_plot + '_{}'.format(criteria)\n",
    "    save_path = os.path.join(plot_dir, base_sample + '_hm_legend.png')  \n",
    "    print(save_path)\n",
    "    wrapper_legend(file_pair['eth'], get_idx, save_path, save)\n",
    "    for key in key_order:\n",
    "        if 'percent' in key:\n",
    "            print(key)\n",
    "            save_path = os.path.join(plot_dir, base_sample + '_{}.png'.format(key))\n",
    "            print(save_path)\n",
    "            heatmap2d(np.array(heatmap_data[key])[:,get_idx][get_idx,:].T, save_path, save)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myimmuno3_light",
   "language": "python",
   "name": "myimmuno3_light"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
