{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "851b2b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from Bio import SeqIO\n",
    "import argparse\n",
    "import os \n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import timeit\n",
    "import argparse\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc4ea0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pep_ids_df(fa_path):\n",
    "    Ids = set()\n",
    "    pep_to_id = {}\n",
    "    for seq in SeqIO.parse(fa_path,'fasta'):\n",
    "        Ids.add(seq.seq)\n",
    "        assert(seq.seq not in pep_to_id)\n",
    "        pep_to_id[str(seq.seq)] = seq.id\n",
    "    df =  pd.DataFrame(pep_to_id.keys(), pep_to_id.values()).reset_index()\n",
    "    df = df.rename({'index':'protein id', 0:'sequence'}, axis = 1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "592aae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_experiment_FDR(select_rows_pipeline, df_search, save_folder, sample, create_sample_subfolder):\n",
    "    '''Selects all the rows from the initial experiment\n",
    "    Save'''\n",
    "    df_search_i = df_search.reset_index()\n",
    "    for experiment_id in select_rows_pipeline:\n",
    "        print(f'.....{experiment_id}')\n",
    "\n",
    "        df_experiment = df_search_i.loc[list(select_rows_pipeline[experiment_id])]\n",
    "        df_experiment = df_experiment.drop_duplicates()\n",
    "\n",
    "\n",
    "        if create_sample_subfolder:\n",
    "            path_save = os.path.join(save_folder, sample, create_sample_subfolder)\n",
    "        else:\n",
    "            path_save = os.path.join(save_folder, sample)\n",
    "\n",
    "        Path(path_save).mkdir(parents=True, exist_ok=True)\n",
    "        path_save = os.path.join(path_save, f'tsearch-{experiment_id}.txt')\n",
    "        print(path_save)\n",
    "        df_experiment.to_csv(path_save, sep = '\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "683887b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_search_result(id_to_exp, id_to_SearchRow):\n",
    "    select_rows = defaultdict(set)\n",
    "    for pep_idx, exp_list in id_to_exp.items():\n",
    "        for experiment in exp_list:\n",
    "            peptide_rows = id_to_SearchRow[pep_idx]\n",
    "            if peptide_rows:\n",
    "                select_rows[experiment].update(peptide_rows)\n",
    "    return select_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b7589b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_result_rows(df_search):\n",
    "    id_to_row = defaultdict(list)\n",
    "    for i, idx in enumerate(df_search['protein id']):\n",
    "        if idx is np.nan:\n",
    "            print('ERROR: Search not successful on all fractions of sample. Please RERUN')\n",
    "        for name_ in idx.split(','):\n",
    "            if 'pepID' not in name_:\n",
    "                continue\n",
    "            pep_ix = int(name_.split('-')[1].split('(')[0])\n",
    "            id_to_row[pep_ix].append(i)\n",
    "    return id_to_row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56521d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reader_experiments(list_experiments):\n",
    "    '''Read files with path lists'''\n",
    "    with open(list_experiments, 'r') as f:\n",
    "        path_dict = {}\n",
    "        for i in f.readlines():\n",
    "            sample_name = os.path.basename(i.strip()).split('_')[1]\n",
    "            sample_short = '-'.join(sample_name.split('-')[0:3])\n",
    "            path_dict[sample_short] = i.strip()\n",
    "    return path_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3f8ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiments_maps(path):\n",
    "    '''Extract experiment maps'''\n",
    "    df = pd.read_csv(path, sep = '\\t')\n",
    "    id_to_pep = {}\n",
    "    id_to_exp = {}\n",
    "    exp_to_id = defaultdict(list)\n",
    "    for i, row in df.iterrows():\n",
    "        id_to_pep[row['peptide_id']] = row['peptide_sequence']\n",
    "        id_to_exp[row['peptide_id']] = row['experiment_ids'].split(';')\n",
    "\n",
    "    for k, v in id_to_exp.items():\n",
    "        for ID in v:\n",
    "            exp_to_id[ID].append(k)\n",
    "    return id_to_pep, id_to_exp, exp_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d487c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUTS\n",
    "fa_path= '/cluster/work/grlab/projects/projects2020_OHSU/proteomics_fixMerge_25012024/OHSU/TCGA-61-2008/trypsine_digest/peptide-extracted-filter-unique.fasta'\n",
    "#ETH_tryptic_peptides = '/cluster/work/grlab/projects/projects2020_OHSU/proteomics_fixMerge_25012024/ETH/TCGA-61-2008/trypsine_digest/\n",
    "list_experiments='/cluster/work/grlab/projects/projects2020_OHSU/share_OHUS_PNLL/current_OHSU_experiments_per_peptides_list.txt'\n",
    "samples = ['TCGA-61-2008']\n",
    "create_sample_subfolder = ''\n",
    "save_folder = '~'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b49d72f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a5a092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_all = reader_experiments(list_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bbf33dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...read tryptic peptides\n"
     ]
    }
   ],
   "source": [
    "print('...read tryptic peptides')\n",
    "df_pep_sample = get_pep_ids_df(fa_path)\n",
    "\n",
    "print('...process experiment map')\n",
    "id_to_pep, id_to_exp, exp_to_id = experiments_maps(exp_all[sample])\n",
    "print(len(id_to_exp))\n",
    "\n",
    "print('...extract rows IDS corresponding to peptides')\n",
    "id_to_SearchRow = search_result_rows(df_pep_sample)\n",
    "print(len(id_to_SearchRow))\n",
    "\n",
    "print('...extract rows needed to reconstruct experiments')\n",
    "select_rows = select_search_result(id_to_exp, id_to_SearchRow)\n",
    "print(len(select_rows))\n",
    "\n",
    "\n",
    "print('...save experiments')\n",
    "reconstruct_experiment_FDR(select_rows, df_pep_sample, save_folder, sample, create_sample_subfolder=create_sample_subfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf19f24f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fed69d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b11fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='separates a joint reindexed file into one file per pipeline with the original indexes')\n",
    "    parser.add_argument(\"--file-joint\", help='tide search file on union of pipelines to separate in two pipelines')\n",
    "    parser.add_argument(\"--map-eth-file\", help='file for eth containing the mapping table between original ids and shared ids')\n",
    "    parser.add_argument(\"--map-ohsu-file\",help='file for ohsu containing the mapping table between original ids and shared ids')\n",
    "    parser.add_argument(\"--save-folder\",help='base folder to save results')\n",
    "    args = parser.parse_args()\n",
    "    print(args)\n",
    "    tide_pipeline_split(args.file_joint, args.map_eth_file, args.map_ohsu_file, args.save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6f854c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE \n",
    "# Write the wrapper\n",
    "# Write the command line"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
