{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdfc0579-751c-4820-a4a7-7cb6e2af5209",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Import libraries](#1)\n",
    "- [Download tables](#2)\n",
    "- [Process tables](#3)\n",
    "- [Download plots](#4)\n",
    "- [Download plots with log10](#5)\n",
    "- [Story of coordinates](#6)\n",
    "- [Story of coordinates (log10)](#7)\n",
    "- [Story of coordinates audit](#8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b445745b-644b-4c4b-944f-15a3b351fc2a",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137108a2-eb05-4dc6-9f07-da810902c7c3",
   "metadata": {},
   "source": [
    "The script is focused on setting up an environment for data analysis and visualization. It imports a suite of libraries and modules that are essential for statistical computing, data manipulation, progress tracking, file system operations, and generating visualizations such as plots and Venn diagrams. The specific libraries imported include pandas for data structures, numpy for numerical operations, tqdm for progress bars, glob for file path retrieval, os for operating system interaction, matplotlib and seaborn for plotting and graphical representations, and matplotlib_venn for creating Venn diagrams.\n",
    "\n",
    "Additionally, the script modifies the system path to include a custom directory, which suggests that the script will use additional custom modules and configuration settings located in this directory. These custom modules, imported with wildcard imports (from config import * and from functions import *)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed2e783-96de-4478-a12a-962a84ad90d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load /cluster/home/myurchikova/github/projects2020_ohsu/eth/learning_Master_thesis/TASKS/func/base_imports.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm \n",
    "import glob\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tarfile\n",
    "import re\n",
    "from matplotlib_venn import venn2, venn2_circles, venn2_unweighted\n",
    "from matplotlib_venn import venn3, venn3_circles\n",
    "import sys\n",
    "sys.path.append(r\"/cluster/home/myurchikova/github/projects2020_ohsu/eth/learning_Master_thesis/TASKS/func\")\n",
    "from config import *\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6001b1b5-3aef-424a-92fb-609b76ca0035",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## Download tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e955f921-d444-4087-b94f-0ee5a1b87049",
   "metadata": {},
   "source": [
    "The code snippet is Python code that uses the pandas library to read two CSV files into DataFrame objects. The pd.read_csv() function is utilized for this purpose, with specified file paths that are constructed using string formatting and variables representing directories and file names. The variables like {SAVE_DIR}, {DIR_CSV}, {DIR_BRCA}, {NAME_TABLES}, {NAME_NON_FILTERING_BRCA}, and {NAME_FILTERING_BRCA} suggest that the file paths are being built dynamically, possibly to handle different datasets or data configurations.\n",
    "\n",
    "The files are read with specific parameters: sep=\"\\t\" indicates that the separator between values in the CSV files is a tab character, which is typical for TSV (Tab-Separated Values) files rather than comma-separated values. The low_memory=False parameter is set to avoid potential low memory warnings when processing large files or files with mixed data types.\n",
    "\n",
    "Two DataFrames are created as a result: out_df_original and out_df_filtered, which refer to the original dataset and a filtered version of it, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11661de2-f45d-440f-bfa6-6c4a43db7b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df_original = pd.read_csv(f'{SAVE_DIR}/{DIR_CSV}/{DIR_BRCA}/{NAME_TABLES}/{NAME_NON_FILTERING_BRCA}', sep=\"\\t\",low_memory=False)\n",
    "out_df_filtered = pd.read_csv(f'{SAVE_DIR}/{DIR_CSV}/{DIR_BRCA}/{NAME_TABLES}/OHSU_BRCA_NEW/{NAME_FILTERING_BRCA}', sep=\";\",low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa4ddf5-030a-429c-8d64-f9d4524af266",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## Process tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca660b8-4403-43aa-90f2-21fbe860add5",
   "metadata": {},
   "source": [
    "It updates the configuration parameters of the matplotlib library to set the font size. The command matplotlib.rcParams.update({'font.size': 4}) modifies the default settings for the font size to 4. This affects all subsequent plots created using matplotlib where no other font size is specified.\n",
    "It imports the math module, which provides access to higher-level mathematical functions and constants. This is a standard Python module commonly used for performing mathematical calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc9ec16-0c47-48d3-bff9-2a82bb3097a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import requirements for fonts\n",
    "\n",
    "matplotlib.rcParams.update({'font.size':4})\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf6f852-d873-473d-979b-62f0d63bd56f",
   "metadata": {},
   "source": [
    "The code snippet in the image outlines a process for manipulating and saving data tables using the pandas library in Python. It starts by assigning two DataFrames, out_df_filtered and out_df_original, to new variables, first_df and second_df, respectively. A third DataFrame, final_df, is then created as a copy of first_df.\n",
    "\n",
    "A new column is added to the out_df_filtered DataFrame, labeled 'sum', which appears to store the sum of several other columns in the DataFrame. These columns include 'size_intersection_coor', 'size_ohsueth_coor', and 'size_ethohsu_coor', though the exact nature of these columns is not clear from the snippet provided.\n",
    "\n",
    "Afterwards, a file path is constructed using a function create_path.create_path() with several variables that likely define different parts of the file path. Finally, the final_df DataFrame is written to a CSV file using the to_csv() method, with tab as the separator and the header included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6949b3ec-b53b-47bd-a53f-f877c82776a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Processing tables & save tables\n",
    "first_df=out_df_filtered\n",
    "second_df=out_df_original\n",
    "final_df = first_df\n",
    "\n",
    "# Adding sum for simple filtration\n",
    "out_df_filtered.insert(loc=4,column='sum',value=final_df['size_intersection_coor']+final_df['size_ohsu\\eth_coor']+final_df['size_eth\\ohsu_coor'])\n",
    "\n",
    "final_path = create_path.create_path(SAVE_DIR,[DIR_CSV,DIR_BRCA,NAME_TABLES,'OHSU_BRCA_NEW',NAME_FINAL_BRCA])\n",
    "\n",
    "final_df.to_csv(final_path,header=True,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca3dce3-31cf-4c00-973f-656c2d96e925",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## Plotting plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4074c4c-62ff-4385-a871-8900174bbc5c",
   "metadata": {},
   "source": [
    "Assignment of data to pandas DataFrames and the creation of a final DataFrame as a copy for further manipulation.\n",
    "Addition of new calculated columns, which suggest an aggregation or summarization of data, indicative of data analysis steps.\n",
    "Application of filters to DataFrames to focus on specific data subsets based on certain conditions or thresholds.\n",
    "Sorting and other data processing operations, including the creation of lists from DataFrame columns, which implies preparation for analysis or visualization.\n",
    "Implementation of conditional logic to handle data based on predefined scenarios, possibly representing different analysis paths or experimental conditions.\n",
    "Generation of file paths for saving outputs, indicating the handling of multiple datasets or output types.\n",
    "Use of custom plotting functions to visualize data comparisons, likely resulting in bar plots.\n",
    "Saving the processed data and plots to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f2f850-e34e-4c8a-a657-5563fe1789a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_df=out_df_filtered\n",
    "second_df=out_df_original\n",
    "\n",
    "final_df = first_df\n",
    "final_path = create_path.create_path(SAVE_DIR,[DIR_CSV,DIR_BRCA,NAME_TABLES,'OHSU_BRCA_NEW',NAME_FINAL_BRCA])\n",
    "\n",
    "final_df.to_csv(final_path,header=True,sep='\\t')\n",
    "diff_tab=pd.DataFrame()\n",
    "# Processing data and drawing grahs for each sample\n",
    "for sample in RESTRICTS_BRCA:\n",
    "    \n",
    "    # Download colums from tables\n",
    "    data_df=final_df.loc[final_df['sample']==sample]\n",
    "    data1_df = data_df.loc[final_df['sum']<800]\n",
    "    data2_df = data_df.loc[final_df['sum']>=800]\n",
    "    data1_df=table_processing.sorting(data1_df)\n",
    "    data2_df=table_processing.sorting(data2_df)\n",
    "    inter_first=list(data1_df['size_intersection_coor'])\n",
    "    s_ETH_first=list(data1_df['size_eth\\ohsu_coor'])\n",
    "    s_OHSU_first=list(data1_df['size_ohsu\\eth_coor'])\n",
    "    filter_foreground_first = list(data1_df['filter_foreground'])\n",
    "    filter_background_first = list(data1_df['filter_background'])\n",
    "    \n",
    "    inter2=list(second_df['size_intersection_coor'].loc[(second_df['sample']==sample)])\n",
    "    s_ETH2=list(second_df['size_eth\\ohsu_coor'].loc[(second_df['sample']==sample)])\n",
    "    s_OHSU2=list(second_df['size_ohsu\\eth_coor'].loc[(second_df['sample']==sample)])\n",
    "    filfor2 = ['']\n",
    "    filbac2 = ['']\n",
    "    if STORY_OF_FILTER_COOR == 'intersection':\n",
    "        inter2_df=out_df_original['inter_coor'].loc[(out_df_original['sample']==sample)]\n",
    "        name='Intersection'\n",
    "    elif STORY_OF_FILTER_COOR == 'ohsu':\n",
    "        inter2_df=out_df_original['ohsu_coor\\eth_coor'].loc[(out_df_original['sample']==sample)]\n",
    "        name ='OHSU/ETH'\n",
    "\n",
    "    inter2_df=out_df_original['inter_coor'].loc[(out_df_original['sample']==sample)]\n",
    "    OHSU_2_df=out_df_original['ohsu_coor\\eth_coor'].loc[(out_df_original['sample']==sample)]\n",
    "    ETH_2_df=out_df_original['eth_coor\\ohsu_coor'].loc[(out_df_original['sample']==sample)]\n",
    "    inter_nf=inter2_df.iloc[0]\n",
    "    ohsu_nf=OHSU_2_df.iloc[0]\n",
    "    eth_nf=ETH_2_df.iloc[0]\n",
    "    inter_nf=inter_nf.replace('\"','').replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").replace(\"{\",\"\").replace(\"}\",\"\").split(', ')\n",
    "    ohsu_nf=ohsu_nf.replace('\"','').replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").replace(\"{\",\"\").replace(\"}\",\"\").split(', ')\n",
    "    eth_nf=eth_nf.replace('\"','').replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").replace(\"{\",\"\").replace(\"}\",\"\").split(', ')\n",
    "\n",
    "\n",
    "\n",
    "    inter_second=list(data2_df['size_intersection_coor'])\n",
    "    s_ETH_second=list(data2_df['size_eth\\ohsu_coor'])\n",
    "    s_OHSU_second=list(data2_df['size_ohsu\\eth_coor'])\n",
    "    filter_foreground_second = list(data2_df['filter_foreground'])\n",
    "    filter_background_second = list(data2_df['filter_background'])\n",
    "    \n",
    "    ySalt=''\n",
    "    OSHU=out_df_filtered['ohsu_coor\\eth_coor'].loc[(out_df_filtered['sample']==sample)]\n",
    "    ETH=out_df_filtered['eth_coor\\ohsu_coor'].loc[(out_df_filtered['sample']==sample)]\n",
    "    \n",
    "    len_ohsu = [len(ohsu_list) for ohsu_list in OSHU]\n",
    "\n",
    "    # Get data to compare\n",
    "    f=final_df.loc[(final_df['sample']==sample)]['filter']\n",
    "    #NF-non-filtered\n",
    "    tab={\n",
    "         'sample':[],\n",
    "         'filter':[],\n",
    "         'JP from Inter NF':[],\n",
    "         'JP from JP NF':[],\n",
    "         'GP from Inter NF':[],\n",
    "         'GP from GP NF':[],\n",
    "         'ff':final_df.loc[final_df['sample']==sample]['filter_foreground'],\n",
    "         'fb':final_df.loc[final_df['sample']==sample]['filter_background'],\n",
    "         }\n",
    "    # Conver Aray in DF to DF structure and compare intersection coordinates in filter with intersection coordinates without filter\n",
    "    for ohsu, filter in zip(OSHU, f):\n",
    "        ohsu=ohsu.replace('\"','').replace(\"{\",\"\").replace(\"}\",\"\").replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").split(', ')\n",
    "        print(\"FFF \",len(inter_nf), len(ohsu))\n",
    "        inter_d=len(inter_d_set:=(set(ohsu) & set(inter_nf)))\n",
    "        ohsu_d=len(ohsu_d_set:=(set(ohsu) & set(ohsu_nf)))\n",
    "        ohsu_out=list(set(ohsu).difference(inter_d_set))\n",
    "        inter_out=list(set(ohsu).difference(ohsu_d_set))\n",
    "        tab['sample'].append(sample)\n",
    "        tab['filter'].append(filter)\n",
    "        tab['JP from Inter NF'].append(inter_d)\n",
    "        tab['JP from JP NF'].append(ohsu_d)\n",
    "        salt=set(ohsu).difference(set(ohsu_nf))\n",
    "        print(f'SALT {salt.difference(set(inter_nf))}')\n",
    "        print(f'Came from OHSU Inter non-filtered {filter}:\\n{inter_d}\\nCame from OHSU non-filtered {filter}:\\n{ohsu_d}\\n')\n",
    "    \n",
    "    for eth, filter in zip(ETH, f):\n",
    "        eth=eth.replace('\"','').replace(\"}\",\"\").replace(\"{\",\"\").replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").split(', ')\n",
    "        print(\"OOO \",len(inter_nf), len(eth))\n",
    "        inter_d=len(inter_d_set:=(set(eth) & set(inter_nf)))\n",
    "        eth_d=len(eth_d_set:=(set(eth) & set(eth_nf)))\n",
    "        eth_out=list(set(eth).difference(inter_d_set))\n",
    "        inter_out=list(set(eth).difference(eth_d_set))\n",
    "        tab['GP from Inter NF'].append(inter_d)\n",
    "        tab['GP from GP NF'].append(eth_d)\n",
    "        salt=set(eth).difference(set(eth_nf))\n",
    "        print(f'SALT {salt.difference(set(inter_nf))}')\n",
    "        print(f'Came from ETH Inter non-filtered {filter}:\\n{inter_d}\\nCame from ETH non-filtered {filter}:\\n{eth_d}\\n')\n",
    "    tab=pd.DataFrame(tab)\n",
    "    diff_tab=pd.concat([diff_tab,tab])\n",
    "    \n",
    "    l_first=len(s_ETH_first)\n",
    "    l_second=len(s_ETH_second)\n",
    "    filfor_first = table_processing.get_filter(filter_foreground_first)\n",
    "    filbac_first = table_processing.get_filter(filter_background_first)\n",
    "    filfor_second = table_processing.get_filter(filter_foreground_second)\n",
    "    filbac_second = table_processing.get_filter(filter_background_second)\n",
    "\n",
    "            \n",
    "    # Combining filters for graph indexing\n",
    "    \n",
    "    fffb_first=[]\n",
    "    for i in range(len(filfor_first)):\n",
    "          fffb_first.append(filfor_first[i]+' '+filbac_first[i])\n",
    "       \n",
    "    fffb2=[]\n",
    "    for i in range(len(filfor2)):\n",
    "          fffb2.append(filfor2[i]+' '+filbac2[i])\n",
    "\n",
    "    fffb_second=[]\n",
    "    for i in range(len(filfor_second)):\n",
    "          fffb_second.append(filfor_second[i]+' '+filbac_second[i])\n",
    "\n",
    "    \n",
    "    # Frame structure building\n",
    "    name = ['coordinates from GP\\JP','coordinates from intersection','coordinates from JP\\GP']\n",
    "\n",
    "    v_first= [s_ETH_first,inter_first, s_OHSU_first]\n",
    "    v_second=[s_ETH_second,inter_second,s_OHSU_second]\n",
    "\n",
    "    \n",
    "    axis2 = {\n",
    "            'coordinates from GP\\JP':s_ETH2,\n",
    "            'coordinates from intersection':inter2,\n",
    "            'coordinates from JP\\GP':s_OHSU2\n",
    "            }\n",
    "    \n",
    "    lg_first = len(filfor_first)\n",
    "    lg2 = len(filfor2)\n",
    "    lg_second = len(filfor_second)\n",
    "    #Plotting sample data\n",
    "    \n",
    "    x_main = filfor_first\n",
    "    x_secondary_first = filbac_first\n",
    "    x_secondary2 = filbac2\n",
    "    x_secondary_second = filbac_second\n",
    "    \n",
    "    plt.figure()\n",
    "\n",
    "\n",
    "\n",
    "    bottom_first =np.zeros(lg_first)\n",
    "    bottom2 =np.zeros(lg2)\n",
    "    bottom_second =np.zeros(lg_second)\n",
    "    \n",
    "    bar_width=0.5\n",
    "    \n",
    "    bar_position_ETH_first = range(len(s_ETH_first))\n",
    "    bar_position_ETH2 = range(len(axis2['coordinates from GP\\JP']))\n",
    "    bar_position_ETH_second = range(len(s_ETH_second))\n",
    "\n",
    "    SALT = salt = PLOT_SORT_BY\n",
    "    path_sample_m1000 =create_path.create_path(SAVE_DIR, [DIR_CSV,DIR_BRCA,NAME_SAMPLES, sample,'OHSU_BRCA_NEW', SALT,'coords',PLOT_TYPE, NAME_PLOT_ABSOLUT_PRETTY_M1000+PNG])\n",
    "    path_sample_l1000 =create_path.create_path(SAVE_DIR, [DIR_CSV,DIR_BRCA,NAME_SAMPLES, sample,'OHSU_BRCA_NEW', SALT,'coords',PLOT_TYPE, NAME_PLOT_ABSOLUT_PRETTY_L1000+PNG])\n",
    "    path_sample_nf =create_path.create_path(SAVE_DIR, [DIR_CSV,DIR_BRCA,NAME_SAMPLES, sample,'OHSU_BRCA_NEW', SALT,'coords',PLOT_TYPE, NAME_PLOT_ABSOLUT_PRETTY_NF+PNG])\n",
    "    path_sample_m1000_pdf =create_path.create_path(SAVE_DIR, [DIR_CSV,DIR_BRCA,NAME_SAMPLES, sample,'OHSU_BRCA_NEW', SALT,'coords',PLOT_TYPE, NAME_PLOT_ABSOLUT_PRETTY_M1000+PDF])\n",
    "    path_sample_l1000_pdf =create_path.create_path(SAVE_DIR, [DIR_CSV,DIR_BRCA,NAME_SAMPLES, sample,'OHSU_BRCA_NEW', SALT,'coords',PLOT_TYPE, NAME_PLOT_ABSOLUT_PRETTY_L1000+PDF])\n",
    "    path_sample_nf_pdf =create_path.create_path(SAVE_DIR, [DIR_CSV,DIR_BRCA,NAME_SAMPLES, sample,'OHSU_BRCA_NEW', SALT,'coords',PLOT_TYPE, NAME_PLOT_ABSOLUT_PRETTY_NF+PDF])\n",
    "\n",
    "    draw_plot.plotting_filtering_barplot(fffb_first,v_first,name,bottom_first,bar_position_ETH_first,sample,filfor_first,x_secondary_first,salt,path_sample_m1000,path_sample_m1000_pdf)\n",
    "    \n",
    "    draw_plot.plotting_nf_barplot(axis2,fffb2,bottom2,sample,path_sample_nf,path_sample_nf_pdf)\n",
    "\n",
    "    draw_plot.plotting_filtering_barplot(fffb_second,v_second,name,bottom_second,bar_position_ETH_second,sample,filfor_second,x_secondary_second,salt,path_sample_l1000,path_sample_l1000_pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8053c36e-81bc-4f13-854e-e4b2d6fb8df8",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## Plotting plots with log10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aa0603-f6f7-40d0-8aed-e5e74282f7fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### WITH LOG\n",
    "# Definition constants\n",
    "import math\n",
    "\n",
    "first_df=out_df_filtered\n",
    "second_df=out_df_original\n",
    "\n",
    "final_df = first_df\n",
    "final_path = create_path.create_path(SAVE_DIR,[DIR_CSV,DIR_BRCA,NAME_TABLES,'OHSU_BRCA_NEW',NAME_FINAL_BRCA])\n",
    "\n",
    "final_df.to_csv(final_path,header=True,sep='\\t')\n",
    "# Processing data and drawing grahs for each sample\n",
    "for sample in RESTRICTS_BRCA:\n",
    "    \n",
    "    # Download colums from tables\n",
    "    data_df=final_df.loc[final_df['sample']==sample]\n",
    "    data1_df = data_df.loc[final_df['sum']<800]\n",
    "    data2_df = data_df.loc[final_df['sum']>=800]\n",
    "    data1_df=table_processing.sorting(data1_df)\n",
    "    data2_df=table_processing.sorting(data2_df)\n",
    "    inter_first=np.log10(data1_df['size_intersection_coor'])\n",
    "    s_ETH_first=np.log10(data1_df['size_eth\\ohsu_coor'])\n",
    "    s_OHSU_first=np.log10(data1_df['size_ohsu\\eth_coor'])\n",
    "    filter_foreground_first = list(data1_df['filter_foreground'])\n",
    "    filter_background_first = list(data1_df['filter_background'])\n",
    "\n",
    "    inter_second=np.log10(data2_df['size_intersection_coor'])\n",
    "    s_ETH_second=np.log10(data2_df['size_eth\\ohsu_coor'])\n",
    "    s_OHSU_second=np.log10(data2_df['size_ohsu\\eth_coor'])\n",
    "    filter_foreground_second = list(data2_df['filter_foreground'])\n",
    "    filter_background_second = list(data2_df['filter_background'])\n",
    "    \n",
    "    #ySalt=''\n",
    "    ySalt=\", log10\"\n",
    "    \n",
    "    l_first=len(s_ETH_first)\n",
    "    l_second=len(s_ETH_second)\n",
    "    filfor_first = table_processing.get_filter(filter_foreground_first)\n",
    "    filbac_first = table_processing.get_filter(filter_background_first)\n",
    "    filfor_second = table_processing.get_filter(filter_foreground_second)\n",
    "    filbac_second = table_processing.get_filter(filter_background_second)\n",
    "\n",
    "            \n",
    "    # Combining filters for graph indexing\n",
    "    \n",
    "    fffb_first=[]\n",
    "    for i in range(len(filfor_first)):\n",
    "          fffb_first.append(filfor_first[i]+' '+filbac_first[i])\n",
    "       \n",
    "\n",
    "    fffb_second=[]\n",
    "    for i in range(len(filfor_second)):\n",
    "          fffb_second.append(filfor_second[i]+' '+filbac_second[i])\n",
    "\n",
    "    \n",
    "    # Frame structure building\n",
    "    name = ['coordinates from GP\\JP','coordinates from intersection','coordinates from JP\\GP']\n",
    "\n",
    "    v_first= [s_ETH_first,inter_first, s_OHSU_first]\n",
    "    v_second=[s_ETH_second,inter_second,s_OHSU_second]\n",
    "\n",
    "    \n",
    "    lg_first = len(filfor_first)\n",
    "    lg_second = len(filfor_second)\n",
    "    #Plotting sample data\n",
    "    \n",
    "    x_main = filfor_first\n",
    "    x_secondary_first = filbac_first\n",
    "    x_secondary_second = filbac_second\n",
    "    \n",
    "    plt.figure()\n",
    "\n",
    "\n",
    "\n",
    "    bottom_first =np.zeros(lg_first)\n",
    "    bottom_second =np.zeros(lg_second)\n",
    "    \n",
    "    bar_width=0.5\n",
    "    \n",
    "    bar_position_ETH_first = range(len(s_ETH_first))\n",
    "    bar_position_ETH_second = range(len(s_ETH_second))\n",
    "\n",
    "    SALT = salt = PLOT_SORT_BY\n",
    "    path_sample_m1000 =create_path.create_path(SAVE_DIR, [DIR_CSV,DIR_BRCA,NAME_SAMPLES, sample,'OHSU_BRCA_NEW', SALT,'coords',PLOT_TYPE, LOGTHM, NAME_PLOT_ABSOLUT_PRETTY_M1000+PNG])\n",
    "    path_sample_l1000 =create_path.create_path(SAVE_DIR, [DIR_CSV,DIR_BRCA,NAME_SAMPLES, sample,'OHSU_BRCA_NEW', SALT,'coords',PLOT_TYPE,LOGTHM, NAME_PLOT_ABSOLUT_PRETTY_L1000+PNG])\n",
    "    path_sample_m1000_pdf =create_path.create_path(SAVE_DIR, [DIR_CSV,DIR_BRCA,NAME_SAMPLES, sample,'OHSU_BRCA_NEW', SALT,'coords',PLOT_TYPE,LOGTHM, NAME_PLOT_ABSOLUT_PRETTY_M1000+PDF])\n",
    "    path_sample_nf_pdf =create_path.create_path(SAVE_DIR, [DIR_CSV,DIR_BRCA,NAME_SAMPLES, sample,'OHSU_BRCA_NEW', SALT,'coords',PLOT_TYPE,LOGTHM, NAME_PLOT_ABSOLUT_PRETTY_NF+PDF])\n",
    "\n",
    "    draw_plot.plotting_filtering_barplot(fffb_first,v_first,name,bottom_first,bar_position_ETH_first,sample,filfor_first,x_secondary_first,salt,path_sample_m1000,path_sample_m1000_pdf, ySalt=ySalt)\n",
    "    \n",
    "\n",
    "    draw_plot.plotting_filtering_barplot(fffb_second,v_second,name,bottom_second,bar_position_ETH_second,sample,filfor_second,x_secondary_second,salt,path_sample_l1000,path_sample_l1000_pdf, ySalt=ySalt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc628c74-4a1a-404e-a264-14ede40c0221",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "## Building plots for story of coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e57d58b-3a22-46d9-989a-b712b80a7200",
   "metadata": {},
   "source": [
    "Extracts unique samples from a DataFrame called diff_tab. Filters out specific rows from this DataFrame based on the current sample in the loop. Sorts the data using custom sorting functions applied to two separate subsets of the data, named df_JP and df_GP, possibly representing different groups or types of samples. Retrieves filter values for each group from the 'filter' column. Creates lists for further manipulation, with prefixes like FF_ and FB_, potentially representing different conditions or classifications within each group. Calculates bar positions for plotting, which will likely be used to determine where bars should be placed on a bar chart. Generates file paths for saving the plots, using a custom create_path function, which combines several variables to form the full path. Calls custom plotting functions to generate plots for each group and saves the figures as PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c63b6f2-ce00-45fd-b7c8-9eb769ead50f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "restricts = diff_tab['sample'].unique()\n",
    "for sample in restricts:\n",
    "    samples_table = diff_tab.loc[diff_tab['sample']==sample]\n",
    "    \n",
    "    df_JP=samples_table\n",
    "    df_GP=samples_table\n",
    "    df_JP=table_processing.sorting_JP(df_JP)\n",
    "    df_GP=table_processing.sorting_GP(df_GP)\n",
    "    \n",
    "    \n",
    "    FILTER_JP=df_JP['filter']\n",
    "    FILTER_GP=df_GP['filter']\n",
    "\n",
    "    \n",
    "    JP_INTER_NF=df_JP['JP from Inter NF']\n",
    "    JP_JP_NF=df_JP['JP from JP NF']\n",
    "    GP_INTER_NF=df_GP['GP from Inter NF']\n",
    "    GP_GP_NF=df_GP['GP from GP NF']\n",
    "\n",
    "    \n",
    "    FF_JP=df_JP['ff']\n",
    "    FB_JP=df_JP['fb']\n",
    "    FF_GP=df_GP['ff']\n",
    "    FB_GP=df_GP['fb']\n",
    "\n",
    "    \n",
    "    bar_position_JP=range(len(FF_JP))\n",
    "    bar_position_GP=range(len(FF_GP))\n",
    "\n",
    "    \n",
    "    path_sample_JP =create_path.create_path(SAVE_DIR, [DIR_CSV,DIR_BRCA,NAME_SAMPLES, sample,'OHSU_BRCA_NEW', SALT,'coords',PLOT_TYPE, NAME_PLOT_JP+PNG])\n",
    "    path_sample_JP_pdf =create_path.create_path(SAVE_DIR, [DIR_CSV,DIR_BRCA,NAME_SAMPLES, sample,'OHSU_BRCA_NEW', SALT,'coords',PLOT_TYPE, NAME_PLOT_JP+PDF])\n",
    "    path_sample_GP =create_path.create_path(SAVE_DIR, [DIR_CSV,DIR_BRCA,NAME_SAMPLES, sample,'OHSU_BRCA_NEW', SALT,'coords',PLOT_TYPE, NAME_PLOT_GP+PNG])\n",
    "    path_sample_GP_pdf =create_path.create_path(SAVE_DIR, [DIR_CSV,DIR_BRCA,NAME_SAMPLES, sample,'OHSU_BRCA_NEW', SALT,'coords',PLOT_TYPE, NAME_PLOT_GP+PDF])\n",
    "        \n",
    "    # print(filters)\n",
    "    plt.figure()\n",
    "\n",
    "\n",
    "    draw_plot.plotting_JP_GP(FILTER_JP,JP_INTER_NF,JP_JP_NF,sample,bar_position_JP,FF_JP,FB_JP,path_sample_JP,path_sample_JP_pdf)\n",
    "    draw_plot.plotting_JP_GP(FILTER_GP,GP_INTER_NF,GP_GP_NF,sample,bar_position_GP,FF_GP,FB_GP,path_sample_GP,path_sample_GP_pdf,JP=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a399dc-a5c7-4668-a6e3-48df7b38f0cc",
   "metadata": {},
   "source": [
    "<a name='7'></a>\n",
    "## Building plots for story of coordinates with log10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcc510b-b8c9-40a8-a39c-6711be9f16b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WITH LOG \n",
    "restricts = diff_tab['sample'].unique()\n",
    "for sample in restricts:\n",
    "    samples_table = diff_tab.loc[diff_tab['sample']==sample]\n",
    "    \n",
    "    df_JP=table_processing.sorting_JP(samples_table)\n",
    "    df_GP=table_processing.sorting_GP(samples_table)\n",
    "    \n",
    "    \n",
    "    FILTER_JP=df_JP['filter']\n",
    "    FILTER_GP=df_GP['filter']\n",
    "\n",
    "    \n",
    "    JP_INTER_NF=np.log10(df_JP['JP from Inter NF'])\n",
    "    JP_JP_NF=np.log10(df_JP['JP from JP NF'])\n",
    "    GP_INTER_NF=np.log10(df_GP['GP from Inter NF'])\n",
    "    GP_GP_NF=np.log10(df_GP['GP from GP NF'])\n",
    "\n",
    "    \n",
    "    FF_JP=df_JP['ff']\n",
    "    FB_JP=df_JP['fb']\n",
    "    FF_GP=df_GP['ff']\n",
    "    FB_GP=df_GP['fb']\n",
    "\n",
    "    \n",
    "    bar_position_JP=range(len(FF_JP))\n",
    "    bar_position_GP=range(len(FF_GP))\n",
    "\n",
    "    \n",
    "    path_sample_JP =create_path.create_path(SAVE_DIR, [DIR_CSV,DIR_BRCA,NAME_SAMPLES, sample,'OHSU_BRCA_NEW', SALT,'coords',PLOT_TYPE, NAME_PLOT_JP+PNG])\n",
    "    path_sample_JP_pdf =create_path.create_path(SAVE_DIR, [DIR_CSV,DIR_BRCA,NAME_SAMPLES, sample,'OHSU_BRCA_NEW', SALT,'coords',PLOT_TYPE, NAME_PLOT_JP+PDF])\n",
    "    path_sample_GP =create_path.create_path(SAVE_DIR, [DIR_CSV,DIR_BRCA,NAME_SAMPLES, sample,'OHSU_BRCA_NEW', SALT,'coords',PLOT_TYPE, NAME_PLOT_GP+PNG])\n",
    "    path_sample_GP_pdf =create_path.create_path(SAVE_DIR, [DIR_CSV,DIR_BRCA,NAME_SAMPLES, sample,'OHSU_BRCA_NEW', SALT,'coords',PLOT_TYPE, NAME_PLOT_GP+PDF])\n",
    "        \n",
    "    # print(filters)\n",
    "    plt.figure()\n",
    "    draw_plot.plotting_JP_GP(FILTER_JP,JP_INTER_NF,JP_JP_NF,sample,bar_position_JP,FF_JP,FB_JP,path_sample_JP,path_sample_JP_pdf,ySalt=', log10')\n",
    "\n",
    "    plt.figure()\n",
    "    draw_plot.plotting_JP_GP(FILTER_GP,GP_INTER_NF,GP_GP_NF,sample,bar_position_GP,FF_GP,FB_GP,path_sample_GP,path_sample_GP_pdf,JP=False,ySalt=', log10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6197320-a3a5-4b5d-89f0-339a4aa9b2a3",
   "metadata": {},
   "source": [
    "<a name='8'></a>\n",
    "## Story of coordinates audit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed02b7c-739c-4ca7-bb7f-d8d713f7812f",
   "metadata": {},
   "source": [
    "Selects subsets of data from two DataFrames out_df_filtered and out_df_original based on the sample identifier 'TCGAA00JMO1A21RA05607'. Retrieves specific columns from these subsets, which may represent coordinates or other types of genomic or biomedical data. Conducts a series of string replacements and splits on these columns to clean or reformat the data. Computes the lengths of the processed data lists, which may be used to quantify the data or for subsequent analysis. Prints out the lengths of these lists, providing a simple textual output that indicates the size of the data subsets related to the OHSU and ETH identifiers within the context of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85e953d-d777-4555-83b3-b2dc7894ec97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_fil=out_df_filtered\n",
    "data_nf=out_df_original\n",
    "OSHU=data_fil['ohsu_coor\\eth_coor'].loc[(out_df_filtered['sample']=='TCGAAOA0JM01A21RA05607')]\n",
    "ETH=data_fil['eth_coor\\ohsu_coor'].loc[(out_df_filtered['sample']=='TCGAAOA0JM01A21RA05607')]\n",
    "inter2_df=data_nf['inter_coor'].loc[(out_df_original['sample']=='TCGAAOA0JM01A21RA05607')]\n",
    "OHSU_2_df=data_nf['ohsu_coor\\eth_coor'].loc[(out_df_original['sample']=='TCGAAOA0JM01A21RA05607')]\n",
    "ETH_2_df=data_nf['eth_coor\\ohsu_coor'].loc[(out_df_original['sample']=='TCGAAOA0JM01A21RA05607')]\n",
    "inter_nf=inter2_df.iloc[0]\n",
    "ohsu_nf=OHSU_2_df.iloc[0]\n",
    "eth_nf=ETH_2_df.iloc[0]\n",
    "inter_nf=inter_nf.replace('\"','').replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").split(', ')\n",
    "ohsu_nf=ohsu_nf.replace('\"','').replace(\"{\",\"\").replace(\"}\",\"\").replace(\"'\",\"\").split(', ')\n",
    "eth_nf=eth_nf.replace('\"','').replace(\"{\",\"\").replace(\"}\",\"\").replace(\"'\",\"\").split(', ')\n",
    "len_ohsu = [ohsu_list.replace('\"','').replace(\"{\",\"\").replace(\"}\",\"\").replace(\"'\",\"\").split(', ') for ohsu_list in OSHU]\n",
    "len_eth = [eth_list.replace('\"','').replace(\"{\",\"\").replace(\"}\",\"\").replace(\"'\",\"\").split(', ') for eth_list in ETH]\n",
    "for ohsu in len_ohsu:\n",
    "    print(f\"len ohsu {len(ohsu)},\\tfrom OHSU NF{len(set(ohsu) & set(ohsu_nf))},\\tfrom INTER NF {len(set(ohsu) & set(inter_nf))},\\tfrom ETH NF {len(set(ohsu) & set(eth_nf))}\")\n",
    "print(TT)\n",
    "for eth in len_eth:\n",
    "    print(f\"len eth {len(eth)},\\tfrom OHSU NF {len(set(eth) & set(ohsu_nf))},\\tfrom INTER NF {len(set(eth) & set(inter_nf))},\\tfrom ETH NF {len(set(eth) & set(eth_nf))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b75c55-4583-4e9f-8586-9efe9c299557",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_tab.to_csv('story_of_coords.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
