{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:25.729230Z",
     "start_time": "2022-02-01T16:26:24.470589Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np \n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:25.738403Z",
     "start_time": "2022-02-01T16:26:25.733474Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = 'filter_TCGA-AO-A0JM-01A-21R-A056-07.all '#'TCGA-A2-A0SX-01A-12R-A084-07.all' #'TCGA-A2-A0D2-01A-21R-A034-07.all'\n",
    "background = 'commit_d4aee54_GTEXcore'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1. Get the all sample experiement longlist: \n",
    "Use cut and unique in bash\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:25.750338Z",
     "start_time": "2022-02-01T16:26:25.747224Z"
    }
   },
   "outputs": [],
   "source": [
    "basefolder = '/cluster/work/grlab/projects/projects2020_OHSU/peptides_generation/v2_v2.5f0752a_conf2_annotFrame_cap0_runs_pya0.17.1/TCGA_Breast_1102'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:25.756297Z",
     "start_time": "2022-02-01T16:26:25.753017Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_folder = os.path.join(basefolder, 'filter_{}/{}'.format(sample, background))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:25.761509Z",
     "start_time": "2022-02-01T16:26:25.758460Z"
    }
   },
   "outputs": [],
   "source": [
    "file_biexon_generated = os.path.join(basefolder, 'cohort_mutNone', 'meta_peptide_pooled_pq.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:25.766829Z",
     "start_time": "2022-02-01T16:26:25.763690Z"
    }
   },
   "outputs": [],
   "source": [
    "file_longlist  = os.path.join(experiment_folder, \n",
    "                         '{}_{}_{}'.format(sample, \n",
    "                                      background.replace('commit_', ''),\n",
    "                                      'kmer_longlist.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:25.772164Z",
     "start_time": "2022-02-01T16:26:25.768973Z"
    }
   },
   "outputs": [],
   "source": [
    "file_meta = os.path.join(experiment_folder, \n",
    "                         '{}_{}_{}'.format(sample, \n",
    "                                      background.replace('commit_', ''),\n",
    "                                      'kmer_peptides_raw333.tsv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:25.777597Z",
     "start_time": "2022-02-01T16:26:25.774878Z"
    }
   },
   "outputs": [],
   "source": [
    "delim = '\\t'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2. Get the metadata and peptides: \n",
    "Done in bash with the command below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:25.823897Z",
     "start_time": "2022-02-01T16:26:25.819989Z"
    }
   },
   "outputs": [],
   "source": [
    "# !charact=$(echo -e '\\t'); for kmer in $(cut -f1 -d ${charact} {file_longlist}); do echo ${kmer},$(grep $kmer {file_biexon_generated}) >> {file_meta}; done"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Use the following command - (most efficient is bash) \n",
    "for kmer in $(cut -f1 -d '     ' filter_TCGA-A2-A0D2-01A-21R-A034-07.all/commit_d4aee54_GTEXcore/TCGA-A2-A0D2-01A-21R-A034-07.all_d4aee54_GTEXcore_kmer_longlist.tsv); do echo ${kmer},$(grep $kmer cohort_mutNone/meta_peptide_pooled_pq.tsv) >> filter_TCGA-A2-A0D2-01A-21R-A034-07.all/commit_d4aee54_GTEXcore/TCGA-A2-A0D2-01A-21R-A034-07.all_d4aee54_GTEXcore_kmer_peptides_raw.tsv; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3. Get the formating of the fasta file done *within this notebook*\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "The fasta headers have the form >pepID-__(peptide ID #)__;jx_pos-__(0-based junction coordinate)__;expected_jx_pep-__(0/1)__;includes_5'-__(0/1)__;includes_3'-__(0/1)__, where:\n",
    "the peptide ID number pepID should match what’s in the experiments-per-peptide file\n",
    "the junction coordinate jx_pos is the 0-based position in the peptide of the amino acid that either overlaps the junction (if the junction is in the middle of a codon), or is immediately before it if the junctiobg expected_jx_pep is 1 in most cases, if there should be a cleavage product that overlaps the junction, or 0 if the amino acid immediately before the junction is a cleavage site and therefore no peptide will actually overlap the junction.\n",
    "the 5' overlap flag includes_5' and 3' overlap flag  includes_3' are 0 if the peptide does not hit the end of the CDS (5’/beginning of the peptide or 3’/end of the peptide respectively) and 1 if the beginning/end of the peptide is the beginning/end of the CDS.\n",
    "The 5' overlap flag includes_5' and 3' overlap flag  includes_3' require going back to the annotation on my side. So I am trying to get this right. Below an example (edited) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4. Get the peptide/ experiment map in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the annotation \n",
    "### Input: Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:26.312145Z",
     "start_time": "2022-02-01T16:26:26.307465Z"
    }
   },
   "outputs": [],
   "source": [
    "ann_path = '/cluster/work/grlab/projects/projects2020_OHSU/annotation/gencode.v32.annotation.gtf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:26.404855Z",
     "start_time": "2022-02-01T16:26:26.390720Z"
    }
   },
   "outputs": [],
   "source": [
    "# From Immunopepper preprocess.py \n",
    "def attribute_item_to_dict(a_item, file_type, feature_type):\n",
    "    \"\"\"  From attribute item in annotation file to get corresponding dictionary\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a_item: str. attribute item\n",
    "    file_type: str. Choose from {'gtf', 'gff', 'gff3'}\n",
    "    feature_type: str. Extract other fields. We only\n",
    "        consider 'CDS', 'mRNA' and 'transcript'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    gtf_dict: dict. store all the necessary data\n",
    "\n",
    "    \"\"\"    \n",
    "    \n",
    "    gtf_dict = {}\n",
    "    if file_type.lower() == 'gtf':\n",
    "        attribute_list = a_item.split('; ')\n",
    "        for attribute_pair in attribute_list:\n",
    "            pair = attribute_pair.split(' ')\n",
    "            gtf_dict[pair[0]] = pair[1][1:-1]\n",
    "    elif file_type.lower() == 'gff3':\n",
    "        attribute_list = a_item.split(';')\n",
    "        for attribute_pair in attribute_list:\n",
    "            pair = attribute_pair.split('=')\n",
    "            gtf_dict[pair[0]] = pair[1]\n",
    "    elif file_type.lower() == 'gff':\n",
    "        gff_dict = {}\n",
    "        attribute_list = a_item.split(';')\n",
    "        for attribute_pair in attribute_list:\n",
    "            pair = attribute_pair.split('=')\n",
    "            gff_dict[pair[0]] = pair[1]  # delete \"\", currently now work on level 2\n",
    "        if feature_type == 'CDS':\n",
    "            gtf_dict['transcript_id'] = gff_dict['Parent']\n",
    "        elif feature_type in {'mRNA', 'transcript'}:  # mRNA or transcript\n",
    "            gtf_dict['gene_id'] = gff_dict['geneID']\n",
    "            gtf_dict['transcript_id'] = gff_dict['ID']\n",
    "            gtf_dict['gene_type'] = gff_dict['gene_type']\n",
    "            gtf_dict['transcript_type'] = gff_dict['transcript_type']\n",
    "\n",
    "    return gtf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:26.490111Z",
     "start_time": "2022-02-01T16:26:26.484089Z"
    }
   },
   "outputs": [],
   "source": [
    "#  From Immunopepper preprocess.py \n",
    "def leq_strand(coord1, coord2, strand):\n",
    "    if strand == \"+\":\n",
    "        return coord1 <= coord2\n",
    "    else:\n",
    "        return coord1 >= coord2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:50.390183Z",
     "start_time": "2022-02-01T16:26:26.602688Z"
    }
   },
   "outputs": [],
   "source": [
    "# From Immunopepper preprocess.py \n",
    "transcript_to_gene_dict = {}    # transcript -> gene id\n",
    "\n",
    "\n",
    "gene_to_transcript_dict = {}    # gene_id -> list of transcripts\n",
    "gene_cds_begin_dict = {}        # gene -> list of first CDS exons\n",
    "\n",
    "transcript_to_cds_dict = {}     # transcript -> list of CDS exons\n",
    "transcript_cds_begin_dict = {}  # transcript -> first exon of the CDS\n",
    "transcript_to_strand = {}\n",
    "\n",
    "file_type = ann_path.split('.')[-1]\n",
    "chromesome_set = set()\n",
    "# collect information from annotation file\n",
    "for line in open(ann_path, 'r'):\n",
    "    if line[0] == '#':\n",
    "        continue\n",
    "    item = line.strip().split('\\t')\n",
    "    chromesome_set.add(item[0])\n",
    "    feature_type = item[2]\n",
    "    attribute_item = item[-1]\n",
    "    attribute_dict = attribute_item_to_dict(attribute_item, file_type, feature_type)\n",
    "    # store relationship between gene ID and its transcript IDs\n",
    "    if feature_type in ['transcript', 'mRNA']:\n",
    "        gene_id = attribute_dict['gene_id']\n",
    "        transcript_id = attribute_dict['transcript_id']\n",
    "        if attribute_dict['gene_type'] != 'protein_coding' or attribute_dict['transcript_type']  != 'protein_coding':\n",
    "            continue\n",
    "        assert (transcript_id not in transcript_to_gene_dict)\n",
    "        transcript_to_gene_dict[transcript_id] = gene_id\n",
    "        if gene_id in gene_to_transcript_dict and transcript_id not in gene_to_transcript_dict[gene_id]:\n",
    "            gene_to_transcript_dict[gene_id].append(transcript_id)\n",
    "        else:\n",
    "            gene_to_transcript_dict[gene_id] = [transcript_id]\n",
    "        # Todo python is 0-based while gene annotation file(.gtf, .vcf, .maf) is one based\n",
    "    elif feature_type == \"CDS\":\n",
    "        parent_ts = attribute_dict['transcript_id']\n",
    "        strand_mode = item[6]\n",
    "        cds_left = int(item[3])-1\n",
    "        cds_right = int(item[4])\n",
    "        frameshift = int(item[7])\n",
    "        transcript_to_strand[parent_ts] = strand_mode\n",
    "        if parent_ts in transcript_to_cds_dict:\n",
    "            transcript_to_cds_dict[parent_ts].append((cds_left, cds_right, frameshift))\n",
    "        else:\n",
    "            transcript_to_cds_dict[parent_ts] = [(cds_left, cds_right, frameshift)]\n",
    "        if strand_mode == \"+\" :\n",
    "            cds_start, cds_stop = cds_left, cds_right\n",
    "        else:\n",
    "            cds_start, cds_stop = cds_right, cds_left\n",
    "\n",
    "        # we only consider the start of the whole CoDing Segment\n",
    "        if parent_ts not in transcript_cds_begin_dict or \\\n",
    "           leq_strand(cds_start, transcript_cds_begin_dict[parent_ts][0], strand_mode):\n",
    "            transcript_cds_begin_dict[parent_ts] = (cds_start, cds_stop, item)\n",
    "\n",
    "# collect first CDS exons for all transcripts of a gene\n",
    "for ts_key in transcript_to_gene_dict:\n",
    "    target_gene = transcript_to_gene_dict[ts_key]\n",
    "    if target_gene not in gene_cds_begin_dict:\n",
    "        gene_cds_begin_dict[target_gene] = []\n",
    "    if ts_key in transcript_cds_begin_dict:\n",
    "        gene_cds_begin_dict[target_gene].append(transcript_cds_begin_dict[ts_key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:50.394626Z",
     "start_time": "2022-02-01T16:26:50.391947Z"
    }
   },
   "outputs": [],
   "source": [
    "# NEED TO SORT THE TRANSCRIPT TO CDS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:50.973490Z",
     "start_time": "2022-02-01T16:26:50.397536Z"
    }
   },
   "outputs": [],
   "source": [
    "# Custom collection of CDS \n",
    "transcript_cds_begin_dict_bis = {}\n",
    "transcript_cds_end_dict_bis = {}\n",
    "\n",
    "gene_cds_begin_dict_bis = defaultdict(list)\n",
    "gene_cds_end_dict_bis = defaultdict(list)\n",
    "\n",
    "# will be in reading order \n",
    "for ts_key in transcript_to_cds_dict:\n",
    "    if transcript_to_strand[ts_key] == '+': # '+'\n",
    "        transcript_cds_begin_dict_bis[ts_key] = (transcript_to_cds_dict[ts_key][0][0],\n",
    "                                                 transcript_to_cds_dict[ts_key][0][1], '+')\n",
    "        transcript_cds_end_dict_bis[ts_key] = (transcript_to_cds_dict[ts_key][-1][0],\n",
    "                                                 transcript_to_cds_dict[ts_key][-1][1], '+')\n",
    "        \n",
    "\n",
    "    else: \n",
    "        transcript_cds_begin_dict_bis[ts_key] = (transcript_to_cds_dict[ts_key][0][1],\n",
    "                                                 transcript_to_cds_dict[ts_key][0][0], '-')\n",
    "        transcript_cds_end_dict_bis[ts_key] = (transcript_to_cds_dict[ts_key][-1][1],\n",
    "                                                 transcript_to_cds_dict[ts_key][-1][0], '-')\n",
    "    \n",
    "    assert(transcript_cds_begin_dict_bis[ts_key][0] == transcript_cds_begin_dict[ts_key][0])\n",
    "    assert(transcript_cds_begin_dict_bis[ts_key][1] == transcript_cds_begin_dict[ts_key][1])\n",
    "\n",
    "# collect first, last CDS exons for all transcripts of a gene\n",
    "for ts_key in transcript_to_gene_dict:\n",
    "    target_gene = transcript_to_gene_dict[ts_key]\n",
    "    gene_cds_begin_dict_bis[target_gene].append(transcript_cds_begin_dict_bis[ts_key])\n",
    "    gene_cds_end_dict_bis[target_gene].append(transcript_cds_end_dict_bis[ts_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:50.977909Z",
     "start_time": "2022-02-01T16:26:50.975461Z"
    }
   },
   "outputs": [],
   "source": [
    "#gene_cds_begin_dict_bis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. Get the experiement/ kmer map "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step a. Get the experiment IDS\n",
    "### Input: J_experiment_map file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:50.984181Z",
     "start_time": "2022-02-01T16:26:50.980341Z"
    }
   },
   "outputs": [],
   "source": [
    "experiement_files = glob.glob(experiment_folder + '/*Uniprot*tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:50.988300Z",
     "start_time": "2022-02-01T16:26:50.985905Z"
    }
   },
   "outputs": [],
   "source": [
    "folder_OHSU = '/cluster/work/grlab/projects/projects2020_OHSU/share_OHUS_PNLL/Aug21_graph_data_updatedfilters'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:50.999113Z",
     "start_time": "2022-02-01T16:26:50.990532Z"
    }
   },
   "outputs": [],
   "source": [
    "exp_map = pd.read_csv(os.path.join(folder_OHSU, 'J_experiment_map.tsv'), sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:51.019639Z",
     "start_time": "2022-02-01T16:26:51.001682Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>motif_filter</th>\n",
       "      <th>min_sample_reads</th>\n",
       "      <th>#_of_cohort_samples</th>\n",
       "      <th>reads_per_cohort_sample</th>\n",
       "      <th>normal_cohort_id</th>\n",
       "      <th>#_normal_samples_allowed</th>\n",
       "      <th>reads_per_normal_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>paired</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>paired</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>paired</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>paired</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>paired</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  motif_filter  min_sample_reads  #_of_cohort_samples  \\\n",
       "0   1             1                 0                    0   \n",
       "1   2             1                 0                    0   \n",
       "2   3             1                 0                    0   \n",
       "3   4             1                 0                    0   \n",
       "4   5             1                 0                    0   \n",
       "\n",
       "   reads_per_cohort_sample normal_cohort_id  #_normal_samples_allowed  \\\n",
       "0                        0           paired                         0   \n",
       "1                        0           paired                         2   \n",
       "2                        0           paired                         2   \n",
       "3                        0           paired                         2   \n",
       "4                        0           paired                        10   \n",
       "\n",
       "   reads_per_normal_sample  \n",
       "0                        0  \n",
       "1                        3  \n",
       "2                       10  \n",
       "3                       -1  \n",
       "4                        3  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:51.028641Z",
     "start_time": "2022-02-01T16:26:51.022636Z"
    }
   },
   "outputs": [],
   "source": [
    "def path_to_condition(all_paths):\n",
    "    '''Converts ETH Names into experimental conditions '''\n",
    "    # None handling added \n",
    "    \n",
    "    #all_paths = [path.replace('None', '-1') for path in all_paths]\n",
    "    sample_expr = [os.path.basename(path).split('ref_SampleLim')[1].split('Cohort')[0]\n",
    "                   for path in all_paths ]\n",
    "\n",
    "    foreground_cohort_expr = [os.path.basename(path).split('CohortLim')[1].split('Across')[0]\n",
    "                                       for path in all_paths ]\n",
    "\n",
    "    foreground_cohort_samples = [os.path.basename(path).split('Across')[1].split('_Filt')[0] \n",
    "                                 for path in all_paths ]\n",
    "\n",
    "    background_cohort_expr = [os.path.basename(path).split('Cohortlim')[1].split('Across')[0]\n",
    "                              for path in all_paths ]\n",
    "\n",
    "    background_cohort_samples = [os.path.basename(path).split('Across')[2].split('_FiltUn')[0]\n",
    "                                 for path in all_paths ]\n",
    "    background_cohort_id = [os.path.basename(path).split('Normals')[1].split('lim')[0] for path in all_paths ]\n",
    "\n",
    "    legend_quant = pd.DataFrame({'min_sample_reads':sample_expr, \n",
    "                  'reads_per_cohort_sample': foreground_cohort_expr, \n",
    "                  '#_of_cohort_samples': foreground_cohort_samples, \n",
    "                  'reads_per_normal_sample': background_cohort_expr,\n",
    "                  '#_normal_samples_allowed' : background_cohort_samples, \n",
    "                    'normal_cohort_id':background_cohort_id, \n",
    "                    'original_name':all_paths})\n",
    "\n",
    "    return legend_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:51.036719Z",
     "start_time": "2022-02-01T16:26:51.030352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiement_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:51.042990Z",
     "start_time": "2022-02-01T16:26:51.039209Z"
    }
   },
   "outputs": [],
   "source": [
    "path_to_table = path_to_condition(experiement_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:51.051015Z",
     "start_time": "2022-02-01T16:26:51.045955Z"
    }
   },
   "outputs": [],
   "source": [
    "path_to_table.loc[path_to_table['min_sample_reads'] == 'None', \n",
    "                  'min_sample_reads'] = 0\n",
    "path_to_table.loc[path_to_table['reads_per_cohort_sample'] == 'None', \n",
    "                  'reads_per_cohort_sample'] = 0\n",
    "path_to_table.loc[path_to_table['#_of_cohort_samples'] == 'None', \n",
    "                  '#_of_cohort_samples'] = 0\n",
    "path_to_table.loc[path_to_table['reads_per_normal_sample'] == 'None', \n",
    "                  'reads_per_normal_sample'] = -1\n",
    "path_to_table.loc[path_to_table['#_normal_samples_allowed'] == 'None', \n",
    "                  '#_normal_samples_allowed'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:51.062538Z",
     "start_time": "2022-02-01T16:26:51.053000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_sample_reads</th>\n",
       "      <th>reads_per_cohort_sample</th>\n",
       "      <th>#_of_cohort_samples</th>\n",
       "      <th>reads_per_normal_sample</th>\n",
       "      <th>#_normal_samples_allowed</th>\n",
       "      <th>normal_cohort_id</th>\n",
       "      <th>original_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [min_sample_reads, reads_per_cohort_sample, #_of_cohort_samples, reads_per_normal_sample, #_normal_samples_allowed, normal_cohort_id, original_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:51.069112Z",
     "start_time": "2022-02-01T16:26:51.064311Z"
    }
   },
   "outputs": [],
   "source": [
    "exp_map.loc[exp_map['normal_cohort_id'] == 'core_GTEx', 'normal_cohort_id'] = 'GtexcoreCohort'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:51.074561Z",
     "start_time": "2022-02-01T16:26:51.071096Z"
    }
   },
   "outputs": [],
   "source": [
    "path_to_table['motif_filter'] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:51.089755Z",
     "start_time": "2022-02-01T16:26:51.077067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_sample_reads\n",
      "int64\n",
      "float64\n",
      "change type\n",
      "\n",
      "\n",
      "reads_per_cohort_sample\n",
      "int64\n",
      "float64\n",
      "change type\n",
      "\n",
      "\n",
      "#_of_cohort_samples\n",
      "int64\n",
      "float64\n",
      "change type\n",
      "\n",
      "\n",
      "reads_per_normal_sample\n",
      "int64\n",
      "float64\n",
      "change type\n",
      "\n",
      "\n",
      "#_normal_samples_allowed\n",
      "int64\n",
      "float64\n",
      "change type\n",
      "\n",
      "\n",
      "normal_cohort_id\n",
      "object\n",
      "float64\n",
      "change type\n",
      "\n",
      "\n",
      "motif_filter\n",
      "int64\n",
      "int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in path_to_table.columns: \n",
    "    if col != 'original_name':\n",
    "        print(col)\n",
    "        print(exp_map[col].dtypes)\n",
    "        print(path_to_table[col].dtypes)\n",
    "        if (exp_map[col].dtypes != path_to_table[col].dtypes) :\n",
    "            print('change type')\n",
    "            if exp_map[col].dtypes == 'int64':\n",
    "                path_to_table[col] = path_to_table[col].astype( 'float64' )\n",
    "            path_to_table[col] = path_to_table[col].astype( exp_map[col].dtypes ) \n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:51.095751Z",
     "start_time": "2022-02-01T16:26:51.091635Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'motif_filter', 'min_sample_reads', '#_of_cohort_samples',\n",
       "       'reads_per_cohort_sample', 'normal_cohort_id',\n",
       "       '#_normal_samples_allowed', 'reads_per_normal_sample'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_map.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:51.102039Z",
     "start_time": "2022-02-01T16:26:51.097855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['min_sample_reads', 'reads_per_cohort_sample', '#_of_cohort_samples',\n",
       "       'reads_per_normal_sample', '#_normal_samples_allowed',\n",
       "       'normal_cohort_id', 'original_name', 'motif_filter'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:51.125721Z",
     "start_time": "2022-02-01T16:26:51.104164Z"
    }
   },
   "outputs": [],
   "source": [
    "id_mapped = path_to_table.merge(exp_map, on = ['min_sample_reads', 'reads_per_cohort_sample', \\\n",
    "                                   '#_of_cohort_samples', 'reads_per_normal_sample', \\\n",
    "                                   '#_normal_samples_allowed',\n",
    "                                   'normal_cohort_id', 'motif_filter'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:51.132901Z",
     "start_time": "2022-02-01T16:26:51.127842Z"
    }
   },
   "outputs": [],
   "source": [
    "id_mapped['filename'] = [os.path.basename(name) for name in id_mapped['original_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:51.141283Z",
     "start_time": "2022-02-01T16:26:51.136573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_mapped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:51.153171Z",
     "start_time": "2022-02-01T16:26:51.143566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_name</th>\n",
       "      <th>id</th>\n",
       "      <th>motif_filter</th>\n",
       "      <th>min_sample_reads</th>\n",
       "      <th>#_of_cohort_samples</th>\n",
       "      <th>reads_per_cohort_sample</th>\n",
       "      <th>normal_cohort_id</th>\n",
       "      <th>#_normal_samples_allowed</th>\n",
       "      <th>reads_per_normal_sample</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [original_name, id, motif_filter, min_sample_reads, #_of_cohort_samples, reads_per_cohort_sample, normal_cohort_id, #_normal_samples_allowed, reads_per_normal_sample, filename]\n",
       "Index: []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_mapped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:51.157836Z",
     "start_time": "2022-02-01T16:26:51.155692Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# path_to_table.loc[(path_to_table['min_sample_reads'] == 0) & \\\n",
    "#             (path_to_table['reads_per_cohort_sample'] == 0) & \\\n",
    "#            (path_to_table['#_of_cohort_samples'] == 2) & \\\n",
    "#            (path_to_table['reads_per_normal_sample'] == -1) & \\\n",
    "#            (path_to_table['#_normal_samples_allowed'] == 2) & \\\n",
    "#            (path_to_table['normal_cohort_id'] == 'GtexcoreCohort') ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step b. Get the longlist of peptides\n",
    "### Input: Peptide files from ETH filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:51.164806Z",
     "start_time": "2022-02-01T16:26:51.160309Z"
    }
   },
   "outputs": [],
   "source": [
    "kmer_file_idx = defaultdict(list) \n",
    "for io, eth_path in enumerate(experiement_files):\n",
    "    eth_path = glob.glob(eth_path + '/*part*')[0]\n",
    "    df_eth = pd.read_csv(eth_path, sep=\"\\t\", usecols = ['kmer'])\n",
    "    df_eth = set(df_eth['kmer'])\n",
    "    base_name = eth_path.split('/')[-2]\n",
    "    idx_exp = id_mapped.loc[id_mapped['filename'] == base_name, 'id'].values[0]\n",
    "    for kmer in df_eth:\n",
    "        kmer_file_idx[kmer].append(str(idx_exp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4. Format the peptide raw file  \n",
    "### Input:  file meta with kmers and bi-exons matching the longlist of the samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:51.169764Z",
     "start_time": "2022-02-01T16:26:51.166981Z"
    }
   },
   "outputs": [],
   "source": [
    "# fields_meta_peptide_dict = ['peptide', 'id', 'readFrame', 'geneName', 'geneChr', 'geneStrand',\n",
    "#                                 'mutationMode',\n",
    "#                                 'junctionAnnotated', 'hasStopCodon', 'isInJunctionList',\n",
    "#                                 'isIsolated', 'variantComb', 'variantSegExpr', 'modifiedExonsCoord',\n",
    "#                                 'originalExonsCoord', 'vertexIdx',\n",
    "#                                 'kmerType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:51.175146Z",
     "start_time": "2022-02-01T16:26:51.171976Z"
    }
   },
   "outputs": [],
   "source": [
    "file_meta = os.path.join(experiment_folder, \n",
    "                         '{}_{}_{}'.format(sample, \n",
    "                                      background.replace('commit_', ''),\n",
    "                                      'kmer_peptides_raw.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:51.180332Z",
     "start_time": "2022-02-01T16:26:51.177508Z"
    }
   },
   "outputs": [],
   "source": [
    "file_save = os.path.join(experiment_folder, \n",
    "                         'G_{}_{}'.format(sample.split('.')[0], \n",
    "                                      'query_peptides.fa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:51.185795Z",
     "start_time": "2022-02-01T16:26:51.182607Z"
    }
   },
   "outputs": [],
   "source": [
    "file_save_experiement= os.path.join(experiment_folder, \n",
    "                         'G_{}_{}'.format(sample.split('.')[0], \n",
    "                                      'experiments_per_peptide.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:26:51.342987Z",
     "start_time": "2022-02-01T16:26:51.187945Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/cluster/work/grlab/projects/projects2020_OHSU/peptides_generation/v2_v2.5f0752a_conf2_annotFrame_cap0_runs_pya0.17.1/TCGA_Breast_1102/filter_filter_TCGA-AO-A0JM-01A-21R-A056-07.all /commit_d4aee54_GTEXcore/G_filter_TCGA-AO-A0JM-01A-21R-A056-07_experiments_per_peptide.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-2fbbac27c8af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Format and create flags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpep_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_save_experiement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mheader_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'peptide_id\\tpeptide_sequence\\texperiment_ids\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader_exp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/cluster/work/grlab/projects/projects2020_OHSU/peptides_generation/v2_v2.5f0752a_conf2_annotFrame_cap0_runs_pya0.17.1/TCGA_Breast_1102/filter_filter_TCGA-AO-A0JM-01A-21R-A056-07.all /commit_d4aee54_GTEXcore/G_filter_TCGA-AO-A0JM-01A-21R-A056-07_experiments_per_peptide.tsv'"
     ]
    }
   ],
   "source": [
    "## Format and create flags \n",
    "pep_idx = 0 \n",
    "with open(file_save_experiement, 'w') as ep:\n",
    "    header_exp = 'peptide_id\\tpeptide_sequence\\texperiment_ids\\n'\n",
    "    ep.write(header_exp)\n",
    "    with open(file_save, 'w') as sp:\n",
    "        with open(file_meta, 'r') as fp:\n",
    "            print(\"open {}\".format(file_meta))\n",
    "            lines = fp.readlines()\n",
    "            ### Iterate over kmers \n",
    "            for line in lines:\n",
    "                if 'modifiedExonsCoord' in line: #header\n",
    "                    continue\n",
    "                line = line.replace('3-exons_9-mer ', '3-exons_9-mer@').replace('2-exons ', '2-exons@')\n",
    "                kmer = line.split(',')[0]\n",
    "                peptides = ','.join(line.split(',')[1:])\n",
    "                peptides = peptides.split('@')\n",
    "                ### Iterate over kmer-associated peptides\n",
    "                for pep in peptides:\n",
    "                    pep = pep.split(',')\n",
    "                    pep_seq = pep[0]\n",
    "                    pep_gene = pep[3]\n",
    "                    pep_orig_coordS = pep[13].split('/')\n",
    "                    pep_modif_coordS = pep[14]\n",
    "                    strand = pep[5]\n",
    "                    has_stop_codon = pep[8]\n",
    "                    if has_stop_codon == '0':\n",
    "                        break \n",
    "                    ### Iterate over original genomic coordinates for include flag\n",
    "                    for pep_orig_coord in pep_orig_coordS:\n",
    "                        pep_orig_coord = pep_orig_coord.split(';')\n",
    "                        pep_orig_coord = [coord for coord in pep_orig_coord if (coord != 'None') and (coord != 'nan')]\n",
    "\n",
    "                        start_cds = [ first_exon[0] for first_exon in \n",
    "                                     gene_cds_begin_dict_bis[pep_gene] ] \n",
    "                        end_cds = [ last_exon[1] for last_exon in \n",
    "                                   gene_cds_end_dict_bis[pep_gene] ] \n",
    "                        ## Get peptide end and start coordinates\n",
    "                        if strand == '+': # Do - strand \n",
    "                            pep_start = np.int(pep_orig_coord[0])\n",
    "                            pep_end = np.int(pep_orig_coord[-1])\n",
    "                        else: \n",
    "                            pep_start = np.int(pep_orig_coord[1])\n",
    "                            pep_end = np.int(pep_orig_coord[-2])\n",
    "\n",
    "                        ## Use end and start coordinates for 3' 5' include flag\n",
    "                        if pep_start in start_cds: # We will always miss things that are new in the graph \n",
    "                            pep_5include = 1\n",
    "                        else: \n",
    "                            pep_5include = 0 \n",
    "                        if (pep_end in end_cds) or (has_stop_codon) == '1':\n",
    "                            pep_3include = 1\n",
    "                        else: \n",
    "                            pep_3include = 0 \n",
    "\n",
    "                    ### Iterate over original genomic coordinates for the junction position flag and between codon flag\n",
    "                    for pep_modi_coord in pep_modif_coordS.split('/'):\n",
    "                        pep_idx +=1\n",
    "                        pep_modi_coord = pep_modi_coord.split(';')\n",
    "                        pep_modi_coord = [coord for coord in pep_modi_coord if (coord != 'None') and (coord != 'nan')]\n",
    "                        if len(pep_modi_coord) <=2:\n",
    "                            continue\n",
    "                        tot_len = 0 \n",
    "                        jx_list = []\n",
    "                        shift = 0 \n",
    "                        shift_list = []\n",
    "                        ## Get nt length of each exon involved -> jx_list, shift_list\n",
    "                        for pair in np.arange(0, len(pep_modi_coord), 2):\n",
    "                            cds = int(pep_modi_coord[pair + 1]) - int(pep_modi_coord[pair])  # 0 based, open right \n",
    "                            cds += shift \n",
    "                            shift = cds % 3\n",
    "                            jx_list.append(cds - shift)\n",
    "                            shift_list.append(shift)\n",
    "                        kmer_len = 9 \n",
    "\n",
    "        #                 for start_pos in np.arange(0, len(pep_seq) - (kmer_len - 1) ):\n",
    "        #                     if pep_seq[start_pos : start_pos + kmer_len ] == kmer:\n",
    "        #                         pos_kmer = start_pos # 0 based, real position = pos_kmer +1\n",
    "        #                 assert(pos_kmer == jx_list[0]/ 3)\n",
    "\n",
    "                        ## Get aa position of the junction\n",
    "                        if shift_list[0]: # junction is inside an amino acid\n",
    "                            aa_junction_pos = int((jx_list[0] / 3)) # because 0 based\n",
    "                            between_codons = 0 \n",
    "                        else: # junction is between amino acids \n",
    "                            aa_junction_pos = int((jx_list[0] / 3) - 1)  # because 0 based\n",
    "                            between_codons = 1\n",
    "                        if strand == '+':\n",
    "                            genome_junction_pos = '{}_{}'.format(pep_modi_coord[1], pep_modi_coord[2])\n",
    "                        else:\n",
    "                            genome_junction_pos = '{}_{}'.format(pep_modi_coord[0], pep_modi_coord[3])\n",
    "\n",
    "\n",
    "                        pep_handle = '>pepID-{};jx_pos-{};between_codons-{};includes_5\\'-{};includes_3\\'-{};gene-{};jx_coord-{}'.format(\n",
    "                        pep_idx, aa_junction_pos, between_codons, pep_5include, pep_3include, pep_gene, genome_junction_pos)\n",
    "                        sp.write(pep_handle + '\\n')\n",
    "                        sp.write(pep_seq + '\\n')\n",
    "                        exp_line = '{}\\t{}\\t{}\\n'.format(pep_idx, \n",
    "                                                         pep_seq,\n",
    "                                                       ';'.join(kmer_file_idx[kmer]))\n",
    "                        ep.write(exp_line)\n",
    "\n",
    "print(file_save_experiement)\n",
    "print(file_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myimmuno3_light",
   "language": "python",
   "name": "myimmuno3_light"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
